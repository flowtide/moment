{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sllm/RL/moment/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from momentfm.utils.data import load_from_tsfile\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from momentfm import MOMENTPipeline\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TS_Dataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            Path to the time series (TS) file.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        \n",
    "        # Load data from the TS file\n",
    "        self.data, self.labels, meta_data = load_from_tsfile(file_path, return_meta_data=True)\n",
    "        print(f\"data.shape={self.data.shape}\")\n",
    "        # Assume data has shape: (n_samples, n_channels, series_length)\n",
    "        self.n_samples, self.n_channels, self.series_length = self.data.shape\n",
    "        \n",
    "        # Normalize each channel of each sample independently\n",
    "        mean = np.mean(self.data, axis=-1, keepdims=True)\n",
    "        std = np.std(self.data, axis=-1, keepdims=True)\n",
    "        std_adj = np.where(std == 0, 1, std)  # Avoid division by zero\n",
    "        self.data = (self.data - mean) / std_adj\n",
    "        \n",
    "        self._length = self.n_samples\n",
    "        self.n_classes = len(meta_data['class_values'])\n",
    "        \n",
    "        # Print dataset summary\n",
    "        print(f\"Dataset Loaded: {file_path} | Samples: {self.n_samples}, Channels: {self.n_channels}, Series Length: {self.series_length}, Classes: {self.n_classes}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], int(self.labels[idx])\n",
    "    \n",
    "    @property\n",
    "    def timeseries(self):\n",
    "        return self.data\n",
    "    \n",
    "    @property\n",
    "    def labels_prop(self):\n",
    "        return self.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, train_dataloader, criterion, optimizer, scheduler, reduction='mean'):\n",
    "    '''\n",
    "    Train only classification head\n",
    "    '''\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch_x, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        batch_x = batch_x.to(device).float()\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        #note that since MOMENT encoder is based on T5, it might experiences numerical unstable issue with float16\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float32):\n",
    "            output = model(x_enc=batch_x, reduction=reduction)\n",
    "            loss = criterion(output.logits, batch_labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    avg_loss = np.mean(losses)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(dataloader, model, criterion, device, phase='val', reduction='mean'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_loss, total_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_labels in dataloader:\n",
    "            batch_x = batch_x.to(device).float()\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            output = model(x_enc=batch_x, reduction=reduction)\n",
    "            loss = criterion(output.logits, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (output.logits.argmax(dim=1) == batch_labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = total_correct / len(dataloader.dataset)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ptbxl_classification` 소스코드에서 코드 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape=(252, 4, 380)\n",
      "Dataset Loaded: ../label_data/2_train_scaled.ts | Samples: 252, Channels: 4, Series Length: 380, Classes: 3\n",
      "data.shape=(1, 4, 380)\n",
      "Dataset Loaded: ../label_data/2_test_scaled.ts | Samples: 1, Channels: 4, Series Length: 380, Classes: 3\n",
      "Num Train Set: 16\n",
      "n_channels=4,num_class=3\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = TS_Dataset(\"../label_data/2_train_scaled.ts\")\n",
    "test_dataset = TS_Dataset(\"../label_data/2_test_scaled.ts\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "val_loader = test_loader\n",
    "\n",
    "print(f\"Num Train Set: {len(train_loader)}\")\n",
    "print(f\"n_channels={train_dataset.n_channels},num_class={train_dataset.n_classes}\")\n",
    "\n",
    "# Initialize the model and move it to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\", \n",
    "    model_kwargs={\n",
    "        'task_name': 'classification',\n",
    "        'n_channels': train_dataset.n_channels,\n",
    "        'num_class': train_dataset.n_classes,\n",
    "        'freeze_encoder': True, # Freeze the patch embedding layer\n",
    "        'freeze_embedder': True, # Freeze the transformer encoder\n",
    "        'freeze_head': False, # The linear forecasting head must be trained\n",
    "        ## NOTE: Disable gradient checkpointing to supress the warning when linear probing the model as MOMENT encoder is frozen\n",
    "        'enable_gradient_checkpointing': False,\n",
    "        # Choose how embedding is obtained from the model: One of ['mean', 'concat']\n",
    "        # Multi-channel embeddings are obtained by either averaging or concatenating patch embeddings \n",
    "        # along the channel dimension. 'concat' results in embeddings of size (n_channels * d_model), \n",
    "        # while 'mean' results in embeddings of size (d_model)\n",
    "        'reduction': 'mean',\n",
    "    },\n",
    "    # local_files_only=True,  # Whether or not to only look at local files (i.e., do not try to download the model).\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (376) must match the size of tensor b (380) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#device = 'cuda:3'\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epoch)):\n\u001b[0;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m evaluate_epoch(val_loader, model, criterion, device, phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, device, train_dataloader, criterion, optimizer, scheduler, reduction)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#note that since MOMENT encoder is based on T5, it might experiences numerical unstable issue with float16\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16 \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_capability()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfloat32):\n\u001b[0;32m---> 16\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_enc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mlogits, batch_labels)\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/RL/moment/momentfm/models/moment.py:227\u001b[0m, in \u001b[0;36mMOMENT.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TimeseriesOutputs:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RL/moment/momentfm/models/moment.py:566\u001b[0m, in \u001b[0;36mMOMENT.forward\u001b[0;34m(self, x_enc, input_mask, mask, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     input_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(x_enc[:, \u001b[38;5;241m0\u001b[39m, :])\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m TASKS\u001b[38;5;241m.\u001b[39mRECONSTRUCTION:\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_enc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m TASKS\u001b[38;5;241m.\u001b[39mEMBED:\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(x_enc\u001b[38;5;241m=\u001b[39mx_enc, input_mask\u001b[38;5;241m=\u001b[39minput_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/RL/moment/momentfm/models/moment.py:295\u001b[0m, in \u001b[0;36mMOMENT.reconstruction\u001b[0;34m(self, x_enc, input_mask, mask, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_generator\u001b[38;5;241m.\u001b[39mgenerate_mask(x\u001b[38;5;241m=\u001b[39mx_enc, input_mask\u001b[38;5;241m=\u001b[39minput_mask)\n\u001b[1;32m    293\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mto(x_enc\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# mask: [batch_size x seq_len]\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m x_enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalizer(x\u001b[38;5;241m=\u001b[39mx_enc, mask\u001b[38;5;241m=\u001b[39m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Prevent too short time-series from causing NaNs\u001b[39;00m\n\u001b[1;32m    297\u001b[0m x_enc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnan_to_num(x_enc, nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, posinf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, neginf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (376) must match the size of tensor b (380) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epoch = 5\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.head.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=epoch * len(train_loader))\n",
    "#device = 'cuda:3'\n",
    "\n",
    "for i in tqdm(range(epoch)):\n",
    "    train_loss = train_epoch(model, device, train_loader, criterion, optimizer, scheduler)\n",
    "    val_loss, val_accuracy = evaluate_epoch(val_loader, model, criterion, device, phase='test')\n",
    "    print(f'Epoch {i}, train loss: {train_loss}, val loss: {val_loss}, val accuracy: {val_accuracy}')\n",
    "\n",
    "test_loss, test_accuracy = evaluate_epoch(test_loader, model, criterion, device, phase='test')\n",
    "print(f'Test loss: {test_loss}, test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "# Load the test dataset\n",
    "test_dataset = StockDataset(data_split=\"test\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "t1 = time.time()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    #for data, input_mask, labels in test_dataloader:\n",
    "    for data, labels in test_dataloader:\n",
    "        # Move data to the appropriate device\n",
    "        data = data.to(device, dtype=torch.float32)\n",
    "        labels = labels.to(device)\n",
    "        #input_mask = input_mask.to(device) if input_mask is not None else None\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(x_enc=data)\n",
    "\n",
    "        if output is None or output.logits is None:\n",
    "            raise ValueError(\"The model's output is None. Check the model's forward implementation.\")\n",
    "\n",
    "        logits: TimeseriesOutputs = output.logits\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(logits, dim=1)  # Get the predicted class indices\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Save all labels and predictions for metric computation\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "test_loss /= len(test_dataloader)\n",
    "accuracy = 100 * correct / total\n",
    "precision = precision_score(all_labels, all_predictions, average=\"weighted\")\n",
    "recall = recall_score(all_labels, all_predictions, average=\"weighted\")\n",
    "f1 = f1_score(all_labels, all_predictions, average=\"weighted\")\n",
    "\n",
    "# Print metrics\n",
    "\n",
    "print(f\"Num Test Set: {len(test_dataloader)}\")\n",
    "print(f\"Test Loss: {test_loss:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Time taken: {time.time() - t1:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
