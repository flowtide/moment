{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk1/hillk/RL/moment/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from momentfm.utils.data import load_from_tsfile\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from momentfm import MOMENTPipeline\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TS_Dataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            Path to the time series (TS) file.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        \n",
    "        # Load data from the TS file\n",
    "        self.data, self.labels, meta_data = load_from_tsfile(file_path, return_meta_data=True)\n",
    "        print(f\"data.shape={self.data.shape}\")\n",
    "        # Assume data has shape: (n_samples, n_channels, series_length)\n",
    "        self.n_samples, self.n_channels, self.series_length = self.data.shape\n",
    "        \n",
    "        # Normalize each channel of each sample independently\n",
    "        mean = np.mean(self.data, axis=-1, keepdims=True)\n",
    "        std = np.std(self.data, axis=-1, keepdims=True)\n",
    "        std_adj = np.where(std == 0, 1, std)  # Avoid division by zero\n",
    "        self.data = (self.data - mean) / std_adj\n",
    "        \n",
    "        self._length = self.n_samples\n",
    "        self.n_classes = len(meta_data['class_values'])\n",
    "        \n",
    "        # Print dataset summary\n",
    "        print(f\"Dataset Loaded: {file_path} | Samples: {self.n_samples}, Channels: {self.n_channels}, Series Length: {self.series_length}, Classes: {self.n_classes}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], int(self.labels[idx])\n",
    "    \n",
    "    @property\n",
    "    def timeseries(self):\n",
    "        return self.data\n",
    "    \n",
    "    @property\n",
    "    def labels_prop(self):\n",
    "        return self.labels\n",
    "\n",
    "\n",
    "def train_epoch(model, device, train_dataloader, criterion, optimizer, scheduler, reduction='mean'):\n",
    "    '''\n",
    "    Train only classification head\n",
    "    '''\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch_x, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        batch_x = batch_x.to(device).float()\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        #print(f\"batch_x={batch_x.shape} batch_labels={batch_labels}\")\n",
    "\n",
    "        #note that since MOMENT encoder is based on T5, it might experiences numerical unstable issue with float16\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float32):\n",
    "            #print(f\"model: batch_x={batch_x.shape} reduction={reduction}\")\n",
    "            output = model(x_enc=batch_x, reduction=reduction)\n",
    "            #print(f\"model: output.logits={output.logits} batch_labels={batch_labels}\")\n",
    "            loss = criterion(output.logits, batch_labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    avg_loss = np.mean(losses)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def evaluate_epoch(dataloader, model, criterion, device, phase='val', reduction='mean'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_loss, total_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_labels in dataloader:\n",
    "            batch_x = batch_x.to(device).float()\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            output = model(x_enc=batch_x, reduction=reduction)\n",
    "            loss = criterion(output.logits, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (output.logits.argmax(dim=1) == batch_labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = total_correct / len(dataloader.dataset)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ptbxl_classification` 소스코드에서 코드 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape=(253, 4, 376)\n",
      "Dataset Loaded: ../label_data/2_train_scaled.ts | Samples: 253, Channels: 4, Series Length: 376, Classes: 3\n",
      "data.shape=(1, 4, 376)\n",
      "Dataset Loaded: ../label_data/2_test_scaled.ts | Samples: 1, Channels: 4, Series Length: 376, Classes: 3\n",
      "Num Train Set: 253\n",
      "n_channels=4,num_class=3\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk1/hillk/RL/moment/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = TS_Dataset(\"../label_data/2_train_scaled.ts\")\n",
    "test_dataset = TS_Dataset(\"../label_data/2_test_scaled.ts\")\n",
    "\n",
    "batch_size = 1 # 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = test_loader\n",
    "\n",
    "print(f\"Num Train Set: {len(train_loader)}\")\n",
    "print(f\"n_channels={train_dataset.n_channels},num_class={train_dataset.n_classes}\")\n",
    "\n",
    "# Initialize the model and move it to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\", \n",
    "    model_kwargs={\n",
    "        'task_name': 'classification',\n",
    "        'n_channels': train_dataset.n_channels,\n",
    "        'num_class': train_dataset.n_classes,\n",
    "        'freeze_encoder': True, # Freeze the patch embedding layer\n",
    "        'freeze_embedder': True, # Freeze the transformer encoder\n",
    "        'freeze_head': False, # The linear forecasting head must be trained\n",
    "        ## NOTE: Disable gradient checkpointing to supress the warning when linear probing the model as MOMENT encoder is frozen\n",
    "        'enable_gradient_checkpointing': False,\n",
    "        # Choose how embedding is obtained from the model: One of ['mean', 'concat']\n",
    "        # Multi-channel embeddings are obtained by either averaging or concatenating patch embeddings \n",
    "        # along the channel dimension. 'concat' results in embeddings of size (n_channels * d_model), \n",
    "        # while 'mean' results in embeddings of size (d_model)\n",
    "        'reduction': 'mean',\n",
    "    },\n",
    "    # local_files_only=True,  # Whether or not to only look at local files (i.e., do not try to download the model).\n",
    "    ).to(device)\n",
    "\n",
    "model.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([1, 4, 376]) tensor([0])\n"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_labels in train_loader:\n",
    "    print(f\"Batch shape: {batch_x.shape} {batch_labels}\")  # Should be (batch_size, n_channels, 380)\n",
    "    break  # Only check the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: output.logits=tensor([[-0.0337,  0.0188,  0.0415]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0601,  0.0286,  0.0505]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0356,  0.0227,  0.0378]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0728,  0.0177,  0.0215]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0111,  0.0243,  0.0128]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0347,  0.0615,  0.0535]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0361,  0.0635,  0.0474]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0576,  0.0486,  0.0430]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0248, -0.0132,  0.0649]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0596, -0.0126,  0.0649]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0703,  0.0640,  0.0669]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0334,  0.0515,  0.0581]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0488,  0.0747,  0.0540]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0366,  0.0186,  0.0562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0298,  0.0525,  0.0603]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0287,  0.0469,  0.0354]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0508,  0.0476,  0.0500]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0266,  0.0513,  0.0581]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0266,  0.0272,  0.0508]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0356,  0.0062,  0.0325]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0208,  0.0344,  0.0493]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0287,  0.0374,  0.0618]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0471,  0.0457,  0.0437]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0298,  0.0176,  0.0361]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0325,  0.0166,  0.0510]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0430,  0.0044,  0.0664]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0041,  0.0444,  0.0669]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0289,  0.0669,  0.0535]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0278,  0.0503,  0.0544]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0439,  0.0342,  0.0522]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0444,  0.0386,  0.0311]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0396,  0.0591,  0.0574]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0210,  0.0142,  0.0349]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0349,  0.0322,  0.0493]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0505,  0.0625,  0.0361]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0215,  0.0245,  0.0337]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0352,  0.0410,  0.0508]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0474,  0.0464,  0.0493]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0310,  0.0588,  0.0461]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0415,  0.0420,  0.0461]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0420,  0.0513,  0.0527]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0304,  0.0115,  0.0300]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0239,  0.0315,  0.0388]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0508,  0.0000,  0.0586]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0291,  0.0391,  0.0618]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0067, 0.0077, 0.0491]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0166,  0.0349,  0.0796]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0178,  0.0164,  0.0233]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0130,  0.0114,  0.0371]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0317,  0.0339,  0.0349]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0137,  0.0291,  0.0505]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0125,  0.0264,  0.0496]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0391,  0.0131,  0.0552]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0244,  0.0393,  0.0664]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0201,  0.0244,  0.0317]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0342,  0.0046,  0.0549]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0537,  0.0349,  0.0422]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0378,  0.0396,  0.0693]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0123, 0.0028, 0.0496]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0259,  0.0464,  0.0491]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0223, -0.0117,  0.0623]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0430,  0.0222,  0.0588]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0312, -0.0100,  0.0193]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0058,  0.0150,  0.0325]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0557, -0.0356,  0.0452]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0096, 0.0006, 0.0204]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0260,  0.0300,  0.0420]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0153, 0.0025, 0.0205]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0087, 0.0206, 0.0669]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0062, 0.0112, 0.0364]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0410,  0.0100,  0.0234]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0108,  0.0640,  0.0591]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0298,  0.0405,  0.0688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0435,  0.0179,  0.0571]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0310,  0.0386,  0.0349]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0018, 0.0261, 0.0525]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0420,  0.0028,  0.0150]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0223,  0.0233,  0.0574]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0386,  0.0100,  0.0342]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0162, 0.0483, 0.0500]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0018,  0.0425,  0.0253]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0089,  0.0278,  0.0219]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0074,  0.0408,  0.0339]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0142,  0.0564,  0.0398]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0120,  0.0339,  0.0183]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0184, 0.0391, 0.0146]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0220, -0.0080,  0.0087]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0042,  0.0542,  0.0256]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0256,  0.0273,  0.0601]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0005,  0.0276,  0.0403]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0295,  0.0605,  0.0245]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0167,  0.0635,  0.0131]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0063,  0.0425, -0.0030]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0042,  0.0035, -0.0117]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0016, 0.0613, 0.0063]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0133,  0.0386,  0.0320]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0166,  0.0288,  0.0030]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0083,  0.0204,  0.0118]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0095,  0.0376,  0.0034]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0205,  0.0238,  0.0420]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0127,  0.0608,  0.0391]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0093, 0.0525, 0.0056]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0110, 0.0037, 0.0223]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0249,  0.0181, -0.0065]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0051, 0.0825, 0.0253]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0175, 0.0247, 0.0041]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0031, 0.0186, 0.0198]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0062, 0.0038, 0.0332]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0264, -0.0020, -0.0127]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0508, -0.0148, -0.0187]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0054, 0.0283, 0.0037]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0013,  0.0498, -0.0008]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0267,  0.0008, -0.0295]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0131, 0.0352, 0.0102]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0204,  0.0549, -0.0147]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0109, -0.0027, -0.0255]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0493,  0.0300, -0.0139]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0474,  0.0097, -0.0308]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0493,  0.0150, -0.0306]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0723, -0.0039, -0.0288]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0415,  0.0053, -0.0036]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0299,  0.0405, -0.0286]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0649,  0.0295, -0.0148]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0557,  0.0149, -0.0471]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0640, -0.0054, -0.0236]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0188,  0.0070, -0.0215]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0723, -0.0198, -0.0432]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0796,  0.0013, -0.0425]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0728, -0.0134, -0.0146]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0830, -0.0369, -0.0148]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0693, -0.0123, -0.0179]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0894, -0.0165,  0.0069]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0713, -0.0166, -0.0080]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0571, -0.0203,  0.0243]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0747,  0.0087, -0.0095]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0825, -0.0273, -0.0121]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0688, -0.0011, -0.0042]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0527, -0.0371, -0.0288]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0747, 0.0067, 0.0248]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0522, -0.0117,  0.0029]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1084, -0.0286, -0.0304]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0601, -0.0139, -0.0019]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0752,  0.0112, -0.0092]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0718, -0.0605,  0.0249]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0703, -0.0276, -0.0408]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0679, -0.0422, -0.0306]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0649, -0.0388,  0.0144]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0295, -0.0101, -0.0015]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0747,  0.0026, -0.0198]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1050, -0.0410, -0.0254]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0405, -0.0019, -0.0238]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0757,  0.0021, -0.0221]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0605, -0.0178, -0.0182]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0703, -0.0028, -0.0187]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0928, -0.0082, -0.0181]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0684, -0.0037, -0.0114]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0981, -0.0155, -0.0070]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1079, -0.0298, -0.0537]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0610, -0.0106, -0.0349]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0918,  0.0070, -0.0444]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0796,  0.0413, -0.0537]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0771,  0.0127, -0.0532]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0957, -0.0042, -0.0698]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0947,  0.0030, -0.0354]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0703,  0.0289, -0.1074]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1250, -0.0366, -0.0889]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0840, -0.0052, -0.0231]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1084, -0.0371, -0.1099]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0645, -0.0082, -0.0300]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1172, -0.0034, -0.0732]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1113, -0.0674, -0.0864]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1064, -0.0203, -0.0601]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.0474, -0.0835]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1455, -0.0586, -0.0684]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1177, -0.0108, -0.0466]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1748, -0.0786, -0.1182]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1299, -0.0074, -0.0640]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1216, -0.0791, -0.0869]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1514, -0.0090, -0.0620]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1387, -0.0737, -0.0535]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1465, -0.0645, -0.0918]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.0649, -0.0583]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.0840, -0.0894]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1572, -0.1118, -0.0471]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2207, -0.0542, -0.0544]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1846, -0.0923, -0.0879]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1514, -0.0796, -0.0383]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1514, -0.0486, -0.0045]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.0737, -0.0247]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2070, -0.0747, -0.0459]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1973, -0.1396, -0.0884]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1621, -0.0630, -0.0127]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1396, -0.0825, -0.0344]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1348, -0.0503,  0.0327]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1152, -0.0630,  0.0253]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1602, -0.0791, -0.0708]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1309, -0.1001, -0.0203]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1367, -0.0874, -0.0383]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1250, -0.0825,  0.0077]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1328, -0.0737, -0.0649]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0972, -0.0752,  0.0136]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1758, -0.0557, -0.0579]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1689, -0.0864, -0.0464]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1289, -0.0581, -0.0070]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1260, -0.0718, -0.0144]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1465, -0.0425,  0.0022]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1260, -0.0845, -0.0032]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1206, -0.0938,  0.0198]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1089, -0.0796, -0.0273]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.0874, -0.0432]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1641, -0.1025, -0.0175]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1226, -0.1064, -0.0127]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1855, -0.1099, -0.0280]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1309, -0.1113, -0.0114]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1318, -0.1221, -0.0219]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1074, -0.1216,  0.0371]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1260, -0.1138,  0.0255]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0947, -0.1289,  0.0874]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0903, -0.0933,  0.0066]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1226, -0.1089,  0.0060]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0762, -0.0913,  0.0771]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0840, -0.1001,  0.0591]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0962, -0.1177,  0.0579]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1021, -0.0830,  0.0131]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0942, -0.1182,  0.0737]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0869, -0.1050,  0.0762]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0859, -0.0850,  0.0889]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0967, -0.0562,  0.0371]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0835, -0.0801,  0.0201]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0193, -0.0442,  0.0723]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0586, -0.0811,  0.0449]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0757, -0.0518,  0.0325]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0410, -0.0771,  0.0767]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0752, -0.0752,  0.0396]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0996, -0.0664, -0.0037]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1279, -0.0952, -0.0264]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1621, -0.0889, -0.0123]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1260, -0.1104, -0.0275]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1216, -0.1187,  0.0618]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1445, -0.1475,  0.0391]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1221, -0.1348,  0.0498]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1436, -0.1196, -0.0181]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1069, -0.1011,  0.0566]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1465, -0.1123, -0.0232]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1738, -0.1309, -0.0483]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1924, -0.1406, -0.0253]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1562, -0.1318, -0.0083]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1562, -0.1074, -0.0137]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1475, -0.1152, -0.0305]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1245, -0.1348, -0.0002]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:05<00:21,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: output.logits=tensor([[ 0.1187, -0.1260,  0.0605]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1187, -0.1187, -0.0030]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1396, -0.0957,  0.0337]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "Epoch 0, train loss: 1.102164649209486, val loss: 1.2511004209518433, val accuracy: 0.0\n",
      "model: output.logits=tensor([[ 0.1621, -0.1523, -0.0142]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1641, -0.1914,  0.0574]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1504, -0.1709,  0.0359]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1377, -0.2070,  0.0938]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1348, -0.2246,  0.0923]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1406, -0.2070,  0.1221]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0986, -0.2041,  0.1943]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1465, -0.2539,  0.1162]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1182, -0.2598,  0.1279]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1865, -0.2324,  0.0649]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1035, -0.1924,  0.1611]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1338, -0.2051,  0.1177]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0674, -0.2178,  0.1846]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1289, -0.2139,  0.1187]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0713, -0.1846,  0.1387]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0645, -0.1602,  0.1387]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1030, -0.1826,  0.0796]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0449, -0.1338,  0.1465]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0613, -0.1846,  0.1270]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0947, -0.1436,  0.0342]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0825, -0.1436,  0.1396]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0718, -0.1533,  0.1367]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0261, -0.1650,  0.1709]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0796, -0.1250,  0.0869]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0488, -0.1768,  0.1465]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0723, -0.1982,  0.1279]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0391, -0.1768,  0.1826]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0056, -0.1855,  0.2139]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0172, -0.2002,  0.2207]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0154, -0.2217,  0.1914]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0099, -0.2051,  0.2158]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0420, -0.2295,  0.2031]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0503, -0.2314,  0.1836]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0454, -0.2314,  0.1924]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0101, -0.2578,  0.2656]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0574, -0.2363,  0.1914]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1040, -0.2695,  0.1660]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1289, -0.2344,  0.1475]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0610, -0.2520,  0.2676]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1157, -0.2656,  0.1484]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0845, -0.2949,  0.1914]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1338, -0.2910,  0.1226]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1338, -0.2988,  0.1226]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1025, -0.2910,  0.1719]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1396, -0.2314,  0.1050]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2275, -0.2412,  0.0420]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1797, -0.2754,  0.0967]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2354, -0.2598,  0.0527]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2275, -0.2832,  0.0962]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2188, -0.2578,  0.0317]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1865, -0.2451,  0.0679]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2109, -0.2617,  0.0962]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2217, -0.2412,  0.0176]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1572, -0.2012,  0.1260]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1855, -0.1875,  0.0103]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1611, -0.2021,  0.0273]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2158, -0.1709,  0.0192]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1533, -0.2061,  0.0913]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2422, -0.1885, -0.0309]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1689, -0.1758,  0.0549]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1797, -0.2100,  0.0381]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1797, -0.1816, -0.0103]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1934, -0.1973, -0.0168]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1953, -0.1416, -0.0654]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1709, -0.1807, -0.0396]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1592, -0.1523, -0.0244]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1816, -0.1670,  0.0136]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2021, -0.1230, -0.0586]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1641, -0.1152,  0.0013]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1245, -0.0713, -0.0452]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2461, -0.1069, -0.1177]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1475, -0.1162, -0.0090]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1108, -0.1235, -0.0176]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.1172, -0.0208]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1846, -0.1221, -0.0369]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1748, -0.0737, -0.0249]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1436, -0.0908, -0.0583]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.0366, -0.1064]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1426, -0.0874, -0.0618]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0679, -0.0786,  0.0596]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1191, -0.0347, -0.0603]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0835, -0.0027, -0.0623]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0923, -0.0286, -0.0542]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0481, 0.0317, 0.0084]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0542,  0.0427, -0.0452]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0337,  0.0544, -0.0084]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0193,  0.0889, -0.1099]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0267,  0.0933, -0.0835]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0376,  0.0850, -0.1279]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0116,  0.1099, -0.0339]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0820,  0.0942, -0.1680]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0591,  0.0503, -0.1230]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0503,  0.0928, -0.1504]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1050,  0.0674, -0.2236]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1064,  0.1069, -0.2139]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0840,  0.1162, -0.1641]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1650,  0.0601, -0.2188]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1602,  0.0679, -0.2217]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1475,  0.0530, -0.1816]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1167,  0.0479, -0.1416]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0977,  0.0562, -0.0850]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1650,  0.0187, -0.1533]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1875,  0.0006, -0.1660]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2656,  0.0036, -0.2773]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1680, -0.0403, -0.1289]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2363, -0.0498, -0.1699]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2041, -0.1069, -0.1748]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2715, -0.0101, -0.2031]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2305, -0.1040, -0.2031]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2910, -0.0811, -0.2832]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1982, -0.0227, -0.1514]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2441, -0.0776, -0.1660]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2158, -0.0104, -0.1641]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2021, -0.0193, -0.1572]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2373, -0.0214, -0.1709]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2520, -0.0464, -0.2363]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2285, -0.0302, -0.1846]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3203, -0.0396, -0.2930]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3027, -0.0947, -0.2578]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3105, -0.0444, -0.2969]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2480, -0.0192, -0.2148]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.0393, -0.1182]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3203, -0.1060, -0.2490]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2207, -0.0996, -0.1875]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3223, -0.1060, -0.1865]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2402, -0.1172, -0.1216]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3496, -0.1299, -0.1924]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3379, -0.1855, -0.1885]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2773, -0.1855, -0.0991]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2480, -0.1426, -0.0942]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3086, -0.2021, -0.1045]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2656, -0.2090, -0.0437]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2695, -0.1963, -0.0596]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2344, -0.1689, -0.0020]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1650, -0.1357, -0.0104]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2490, -0.1377, -0.0693]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1865, -0.1133, -0.0562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2598, -0.1084, -0.1807]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1875, -0.0684, -0.0361]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2041, -0.0801, -0.0654]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2754, -0.0938, -0.1895]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2520, -0.1006, -0.1816]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1338, -0.0840, -0.0361]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1719, -0.0742, -0.0991]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2041, -0.0618, -0.1533]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2373, -0.0752, -0.1592]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1396, -0.1240, -0.0378]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1846, -0.0859, -0.0786]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2168, -0.0801, -0.1011]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2441, -0.0615, -0.1631]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2441, -0.1055, -0.1572]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1562, -0.0562, -0.0544]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2217, -0.1064, -0.1025]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2432, -0.0825, -0.1387]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2500, -0.0928, -0.1631]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2236, -0.1118, -0.1396]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2178, -0.0957, -0.0623]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2734, -0.1177, -0.1660]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1660, -0.0212, -0.1147]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1348, -0.0342, -0.1045]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1836, -0.0009, -0.1514]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2559, -0.0588, -0.2139]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2871, -0.0310, -0.2695]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1816, -0.0212, -0.1113]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2676, -0.0104, -0.2949]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2285, -0.0081, -0.2100]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1416, -0.0605, -0.0537]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2734, -0.0171, -0.3047]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2031, -0.0508, -0.1855]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1895, -0.0432, -0.1895]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2949, -0.0679, -0.2041]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3066, -0.1108, -0.1816]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3184, -0.0869, -0.2324]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2871, -0.1006, -0.2041]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2363, -0.1221, -0.0938]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3301, -0.1025, -0.3008]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3066, -0.1475, -0.1582]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3105, -0.1177, -0.2061]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2354, -0.1396, -0.0659]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2793, -0.1543, -0.1309]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2715, -0.1465, -0.0889]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3008, -0.1924, -0.0947]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3145, -0.1875, -0.1387]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3066, -0.2168, -0.1787]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2891, -0.1973, -0.1504]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3184, -0.2383, -0.0625]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2754, -0.1602, -0.0996]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1924, -0.2119,  0.0327]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2578, -0.2080, -0.0286]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2656, -0.2178, -0.1099]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3223, -0.2539, -0.1729]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1719, -0.1924,  0.0635]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2539, -0.1982, -0.0542]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0908, -0.1846,  0.1641]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1025, -0.1953,  0.1436]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2373, -0.1387, -0.1279]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1318, -0.1826,  0.0718]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2041, -0.1963, -0.0203]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1387, -0.1270,  0.0063]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1992, -0.1040, -0.0840]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0374, -0.1206,  0.1206]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1914, -0.0996, -0.1084]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2559, -0.1250, -0.1357]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1445, -0.1377,  0.0122]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1377, -0.0874, -0.0493]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0498, -0.0918,  0.0432]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1221, -0.1416, -0.0128]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1777, -0.1289,  0.0135]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1235, -0.1318,  0.0498]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2100, -0.1387, -0.0791]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2051, -0.1611, -0.0742]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1396, -0.2217,  0.0786]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2637, -0.1992, -0.0757]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1602, -0.1875,  0.0079]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1904, -0.1992, -0.0337]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1660, -0.1758, -0.0220]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1157, -0.1650,  0.0352]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0518, -0.1494,  0.1357]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1162, -0.1484,  0.0376]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1582, -0.1387, -0.0493]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0317, -0.1006,  0.1523]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0732, -0.1611,  0.1069]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0654, -0.1245,  0.0869]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1089, -0.0728, -0.0315]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0947, -0.1108,  0.0334]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0962, -0.1641,  0.2773]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0364, -0.1147,  0.1973]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0250, -0.0742,  0.0461]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0435, -0.0986,  0.0703]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0581, -0.0361,  0.1650]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0066, -0.1069,  0.0500]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0947, -0.0952,  0.0173]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0400, -0.0728,  0.0840]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1074, -0.0947,  0.0366]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1230, -0.1211, -0.0342]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1758, -0.0752, -0.0908]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1592, -0.1445, -0.0410]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1030, -0.1299, -0.0500]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0164, -0.1895,  0.1523]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1504, -0.1709,  0.0898]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1050, -0.1748,  0.1206]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2559, -0.1387, -0.1309]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0762, -0.1504,  0.1465]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1953, -0.1445, -0.0688]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2432, -0.1270, -0.1768]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2197, -0.1807, -0.0540]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1416, -0.1445, -0.0276]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0737, -0.1406,  0.1040]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:10<00:15,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: output.logits=tensor([[ 0.1875, -0.1279, -0.0874]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1465, -0.1650,  0.0334]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0466, -0.1709,  0.1104]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1465, -0.1650, -0.0023]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1553, -0.2002,  0.0347]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "Epoch 1, train loss: 1.099123023715415, val loss: 1.2944689989089966, val accuracy: 0.0\n",
      "model: output.logits=tensor([[ 0.2773, -0.1533, -0.1738]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2109, -0.2363,  0.0240]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1875, -0.1787, -0.0023]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1108, -0.2832,  0.1484]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1138, -0.3125,  0.1279]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1582, -0.2773,  0.1367]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0503, -0.3125,  0.2852]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1650, -0.2969,  0.1211]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1865, -0.2559,  0.0977]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2246, -0.2637, -0.0094]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0454, -0.2852,  0.2715]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1641, -0.2988,  0.1611]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0232, -0.2793,  0.3262]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1167, -0.2539,  0.1128]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0554, -0.2305,  0.1572]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0060, -0.2236,  0.2471]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1582, -0.1592, -0.0361]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0544, -0.1768,  0.1118]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-1.2207e-04, -2.1387e-01,  2.1875e-01]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1055, -0.1318, -0.0469]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0449, -0.2207,  0.1846]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0718, -0.2051,  0.1494]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0236, -0.2090,  0.2344]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1035, -0.1523,  0.0613]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0214, -0.2363,  0.1699]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0061, -0.1709,  0.1963]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0281, -0.2041,  0.1602]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0457, -0.2197,  0.2891]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0325, -0.1924,  0.2656]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0266, -0.2676,  0.2275]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0586, -0.2490,  0.3086]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0579, -0.2227,  0.1982]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0454, -0.1963,  0.1196]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0635, -0.2314,  0.1611]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0046, -0.3086,  0.3164]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0674, -0.2695,  0.2168]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1025, -0.2910,  0.1484]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1318, -0.2393,  0.1289]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0026, -0.2754,  0.3281]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0698, -0.2832,  0.1719]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0654, -0.2988,  0.2217]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1104, -0.2773,  0.1553]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2031, -0.3242,  0.0664]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1089, -0.3574,  0.2373]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1602, -0.3164,  0.1348]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2188, -0.2236, -0.0248]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1206, -0.2832,  0.1777]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2334, -0.3203,  0.0737]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.2656,  0.1079]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2246, -0.2422, -0.0206]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1582, -0.2637,  0.0498]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1992, -0.2832,  0.0962]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2676, -0.1865, -0.0330]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0608, -0.2461,  0.1885]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2471, -0.2031, -0.0549]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1953, -0.2871,  0.0557]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1807, -0.2305,  0.0238]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0801, -0.2412,  0.1768]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2617, -0.1660, -0.0747]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1299, -0.2266,  0.0981]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1475, -0.1973,  0.0615]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2041, -0.1768, -0.0403]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1455, -0.2754,  0.0579]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1631, -0.1089, -0.0815]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2275, -0.1592, -0.1338]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0776, -0.1206, -0.0197]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2266, -0.1807, -0.0168]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1855, -0.0520, -0.1406]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1523, -0.0898,  0.0053]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1035, -0.1318,  0.0076]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2695, -0.1064, -0.1611]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0879, -0.1611,  0.1123]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1396, -0.1157,  0.0304]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1514, -0.1260,  0.0286]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1377, -0.1245,  0.0140]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0608, -0.1040,  0.0135]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1562, -0.0540, -0.1250]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1641, -0.0513, -0.1357]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1045, -0.1357, -0.0254]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0001, -0.1064,  0.1187]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1396, -0.0859, -0.1216]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0815,  0.0010, -0.0337]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1113, -0.0850, -0.0576]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0011, -0.0283,  0.0488]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0176,  0.0237, -0.0280]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[0.0010, 0.0095, 0.0129]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0859,  0.0518, -0.1562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0693,  0.0080, -0.0591]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0254,  0.0601, -0.0874]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0381,  0.0369,  0.0518]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1191,  0.0332, -0.2012]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0791,  0.0292, -0.1621]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0659,  0.1040, -0.1738]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1514,  0.0559, -0.2930]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1494,  0.1143, -0.2617]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0791,  0.0957, -0.1748]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1523, -0.0102, -0.2188]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0591,  0.0869, -0.2041]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1123,  0.0254, -0.1777]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0718,  0.0630, -0.1279]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0135,  0.0132,  0.0188]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1436, -0.0222, -0.1270]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1514, -0.0576, -0.1128]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3145, -0.0231, -0.3379]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0522, -0.0212,  0.0227]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2061, -0.0413, -0.1660]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2178, -0.0476, -0.2236]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2598, -0.0138, -0.2598]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3066, -0.0815, -0.2656]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3281, -0.0347, -0.3496]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1201, -0.0014, -0.0845]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2812, -0.0500, -0.2178]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.0618, -0.1602]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1650, -0.0491, -0.1011]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2256, -0.0884, -0.1943]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2012, -0.0146, -0.2559]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1807, -0.0413, -0.1562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3223, -0.0101, -0.3340]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3438, -0.0811, -0.2656]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2754, -0.0060, -0.3340]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1660, -0.0405, -0.1758]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1030, -0.0693, -0.0198]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3359, -0.1191, -0.2461]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2598, -0.0942, -0.2109]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3145, -0.1416, -0.2148]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2002, -0.0918, -0.1816]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3555, -0.1094, -0.3105]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3262, -0.1318, -0.2539]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3203, -0.1621, -0.1748]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2734, -0.1206, -0.1416]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3281, -0.1885, -0.1621]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2637, -0.1836, -0.1104]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2754, -0.1934, -0.0884]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2002, -0.1270,  0.0208]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1504, -0.1826,  0.0317]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2148, -0.1484, -0.0977]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1328, -0.1387,  0.0025]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3125, -0.1025, -0.2891]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0625, -0.0894,  0.0153]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1182, -0.0486, -0.0664]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2812, -0.0598, -0.3145]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3066, -0.0630, -0.2754]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1221, -0.0864, -0.0352]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.0762, -0.1235]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2988, -0.0530, -0.2832]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2812, -0.1025, -0.2344]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1973, -0.1553, -0.0449]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1592, -0.0659, -0.1001]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2539, -0.0947, -0.1445]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2285, -0.0535, -0.2070]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2432, -0.1011, -0.1943]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0840, -0.0781,  0.0036]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2480, -0.1216, -0.1201]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2129, -0.0850, -0.1211]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2578, -0.0991, -0.1660]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1934, -0.1084, -0.1074]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1016, -0.1396,  0.0259]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2793, -0.0742, -0.1836]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1050, -0.0640, -0.0227]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0879, -0.1016,  0.0148]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1494, -0.0879, -0.0483]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2578, -0.0967, -0.1514]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2637, -0.0342, -0.2227]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1035, -0.0613, -0.0188]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2656, -0.0075, -0.2676]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2012, -0.0811, -0.1885]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0693, -0.0535, -0.0009]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2871,  0.0103, -0.3496]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1797, -0.0776, -0.1807]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2197, -0.0801, -0.1885]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3086, -0.0723, -0.2539]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2793, -0.0889, -0.2354]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3066, -0.0320, -0.2871]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2891, -0.0732, -0.2500]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1309, -0.1084, -0.0253]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3750, -0.0051, -0.4121]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2812, -0.1162, -0.1787]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3535, -0.1221, -0.2930]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1973, -0.1357, -0.0562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1992, -0.1016, -0.0942]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2402, -0.1885, -0.0894]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2520, -0.1475, -0.0952]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2812, -0.1475, -0.1807]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3320, -0.2090, -0.1543]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2246, -0.1069, -0.1377]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2949, -0.2061, -0.0918]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2354, -0.1562, -0.0981]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1318, -0.1191,  0.0117]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2617, -0.2178, -0.0356]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2246, -0.1748, -0.1289]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3730, -0.1504, -0.2637]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0791, -0.1514,  0.0645]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2383, -0.1719, -0.0552]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0200, -0.1768,  0.2002]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0542, -0.1914,  0.1689]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2969, -0.1367, -0.2432]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1157, -0.1973,  0.0845]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2422, -0.2041, -0.0952]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1562, -0.1475, -0.0131]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2109, -0.0840, -0.1797]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0032, -0.1240,  0.1465]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2197, -0.0510, -0.1562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2598, -0.0962, -0.2285]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1445, -0.1748,  0.0354]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1514, -0.0588, -0.1143]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0781, -0.1025,  0.0371]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0623, -0.0918,  0.0108]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2012, -0.2041,  0.0046]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1152, -0.1553,  0.0302]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2285, -0.0962, -0.1865]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2734, -0.1807, -0.1201]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1011, -0.1357,  0.0645]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2734, -0.1455, -0.1846]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1680, -0.2148, -0.0057]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2412, -0.1836, -0.1475]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1641, -0.1611, -0.0767]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1206, -0.1279, -0.0371]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0820, -0.1602,  0.0913]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1562, -0.1309, -0.0437]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2266, -0.1055, -0.1924]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0214, -0.1826,  0.1621]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0510, -0.1660,  0.0894]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0508, -0.1147,  0.0251]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1660, -0.0403, -0.1426]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1846, -0.1138, -0.0209]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.1167, -0.2197,  0.3164]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0242, -0.1235,  0.1777]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0938, -0.0698,  0.0347]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1348, -0.1748,  0.0270]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0371, -0.1064,  0.1582]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0430, -0.1416,  0.0679]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1348, -0.1914,  0.0006]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1045, -0.0830,  0.0076]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.1387,  0.0049]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1855, -0.1348, -0.0581]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2432, -0.1123, -0.1396]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1621, -0.1357, -0.0610]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1709, -0.0549, -0.0781]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0042, -0.1963,  0.2070]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0762, -0.1348,  0.0879]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0312, -0.1650,  0.1953]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2383, -0.0967, -0.1445]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0405, -0.1836,  0.2559]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1885, -0.1904, -0.0420]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2773, -0.1494, -0.2021]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2256, -0.1846, -0.0767]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:15<00:10,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: output.logits=tensor([[ 0.1514, -0.1689,  0.0062]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0040, -0.0977,  0.1387]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1562, -0.0986, -0.0889]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1436, -0.1543, -0.0123]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1162, -0.1533,  0.0625]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1670, -0.1338, -0.0762]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1621, -0.0981, -0.0297]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "Epoch 2, train loss: 1.087203557312253, val loss: 1.263718843460083, val accuracy: 0.0\n",
      "model: output.logits=tensor([[ 0.3711, -0.0430, -0.3438]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2383, -0.2354, -0.0361]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2754, -0.1465, -0.1797]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1875, -0.2598,  0.0276]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1748, -0.2676,  0.0254]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1387, -0.2314,  0.0664]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0167, -0.2695,  0.3008]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1914, -0.2793,  0.0040]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2012, -0.2295, -0.0430]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2852, -0.1816, -0.1484]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0635, -0.2480,  0.2793]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2109, -0.2812,  0.0625]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0767, -0.2139,  0.3203]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1250, -0.2100,  0.0615]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0630, -0.2080,  0.1245]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0139, -0.2275,  0.1855]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1592, -0.1445, -0.0884]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0601, -0.1797,  0.0928]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0056, -0.1729,  0.1699]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1729, -0.0977, -0.1660]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0018, -0.1650,  0.1953]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0708, -0.1533,  0.0742]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0515, -0.1816,  0.2314]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1934, -0.1680, -0.0942]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0796, -0.2139,  0.1021]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0747, -0.1924,  0.1309]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0452, -0.1689,  0.0947]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0427, -0.1797,  0.1562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0513, -0.1846,  0.2129]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0664, -0.2227,  0.1191]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0129, -0.2178,  0.2139]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1079, -0.1973,  0.0767]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0898, -0.1826,  0.0352]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1196, -0.2422,  0.0425]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0021, -0.3594,  0.3223]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0928, -0.2354,  0.1533]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1357, -0.2227,  0.0273]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1240, -0.1973,  0.0603]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0583, -0.2715,  0.3379]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1094, -0.2217,  0.0366]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0352, -0.2559,  0.1807]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0879, -0.2373,  0.1074]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1475, -0.2910,  0.0654]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0469, -0.3398,  0.2773]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1206, -0.3203,  0.1592]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1875, -0.1309, -0.0537]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-1.8311e-04, -2.8906e-01,  2.1094e-01]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1904, -0.2988,  0.0830]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0957, -0.2383,  0.1196]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1514, -0.1865, -0.0041]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0771, -0.2129,  0.1270]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1689, -0.2930,  0.1279]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2480, -0.2402, -0.0349]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0118, -0.2334,  0.2637]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1729, -0.2090, -0.0532]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1758, -0.3047,  0.0752]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1787, -0.2061,  0.0344]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0520, -0.2559,  0.2793]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1924, -0.1172, -0.0947]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0493, -0.1807,  0.1484]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1123, -0.2129,  0.0796]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2021, -0.2129, -0.0378]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1357, -0.2656,  0.0586]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1553, -0.1025, -0.1143]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2217, -0.1562, -0.1250]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1123, -0.1279, -0.0239]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1611, -0.2520,  0.0272]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1504, -0.0967, -0.0771]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0493, -0.1338,  0.1069]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0767, -0.2383,  0.0913]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2100, -0.1299, -0.1436]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0110, -0.2217,  0.2295]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0466, -0.1777,  0.1216]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0588, -0.1982,  0.1050]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0542, -0.1230,  0.1006]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0374, -0.1836,  0.0815]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2305, -0.0752, -0.1387]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.0908, -0.1235]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1816, -0.2471,  0.0156]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0349, -0.1729,  0.2344]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2285, -0.1021, -0.1235]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0481, -0.0952,  0.0165]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2051, -0.1748, -0.0728]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0170, -0.1064,  0.1602]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0092, -0.0913,  0.0986]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0059, -0.0952,  0.1211]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1562, -0.0317, -0.1709]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1089, -0.0723,  0.0060]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0781, -0.0623, -0.0454]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0103, -0.1021,  0.1270]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2324, -0.0530, -0.1729]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1602, -0.1128, -0.0654]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0698, -0.0232, -0.0708]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2109,  0.0164, -0.2578]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1260, -0.0225, -0.1670]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0322, -0.0332, -0.0557]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1885, -0.0986, -0.1689]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1250,  0.0036, -0.1494]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1270, -0.1113, -0.0420]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0527, -0.0427,  0.0112]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0356, -0.0679,  0.1543]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1309, -0.1562,  0.0251]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0957, -0.1172, -0.0237]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2559, -0.0036, -0.2676]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0148, -0.1001,  0.0815]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1885, -0.0767, -0.1318]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1875, -0.0520, -0.1680]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1875, -0.0292, -0.1924]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2988, -0.1240, -0.2598]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2988, -0.0248, -0.3535]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0762, -0.0933,  0.0200]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1758, -0.0820, -0.1602]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1680, -0.0923, -0.1182]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1084, -0.0776, -0.0255]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1660, -0.1011, -0.0493]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2432, -0.0850, -0.2520]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1357, -0.0444, -0.0732]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2656, -0.0757, -0.2422]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2910, -0.1309, -0.1748]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2119, -0.0437, -0.2480]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1055, -0.0251, -0.1089]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0168, -0.0986,  0.1328]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2773, -0.1279, -0.1787]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1670, -0.0693, -0.1543]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2324, -0.1396, -0.1494]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1357, -0.1289, -0.0522]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3594, -0.1123, -0.2656]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3184, -0.1299, -0.2812]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2451, -0.1631, -0.1328]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2031, -0.0845, -0.1309]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2734, -0.1582, -0.1592]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2129, -0.1299, -0.1377]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.1250, -0.0757]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0952, -0.1104,  0.0483]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0009, -0.1631,  0.1147]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.0913, -0.0874]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0767, -0.1064,  0.0334]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2559, -0.0320, -0.2754]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0293, -0.1318,  0.1040]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0337, -0.0635,  0.0337]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3223, -0.0757, -0.3672]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3008, -0.0315, -0.3574]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1250, -0.1104,  0.0049]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2061, -0.0981, -0.1084]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3145, -0.0825, -0.3027]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3242, -0.0767, -0.2852]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1377, -0.1943, -0.0020]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1328, -0.0718, -0.0947]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2314, -0.1099, -0.1621]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2207, -0.0371, -0.2061]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2734, -0.1079, -0.2197]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0859, -0.0977,  0.0146]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2373, -0.1680, -0.0791]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1689, -0.0903, -0.0952]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2246, -0.0923, -0.1230]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1455, -0.1514, -0.0515]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0337, -0.1299,  0.1157]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1689, -0.1426, -0.0703]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0000, -0.1787,  0.1128]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0417, -0.1221,  0.0723]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1147, -0.1553,  0.0486]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1885, -0.0928, -0.1045]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2676, -0.1025, -0.2148]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0128, -0.1045,  0.1182]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2490, -0.0747, -0.2236]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1748, -0.0928, -0.1270]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0088, -0.0991,  0.1504]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3281, -0.0201, -0.3516]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1533, -0.1016, -0.0947]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2080, -0.0923, -0.1436]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2910, -0.1016, -0.2168]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3242, -0.1465, -0.1650]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2988, -0.0413, -0.3105]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2461, -0.0403, -0.2578]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0640, -0.1187,  0.0153]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3086, -0.0122, -0.4336]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2314, -0.1328, -0.1387]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2871, -0.1084, -0.2637]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1162, -0.1592,  0.0201]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1592, -0.1260, -0.0564]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2217, -0.1416, -0.0559]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1904, -0.1572, -0.0669]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2422, -0.1196, -0.2051]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2812, -0.1846, -0.1650]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1953, -0.0242, -0.1680]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2217, -0.1943, -0.0417]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2080, -0.1523, -0.0684]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1011, -0.0938,  0.0232]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1855, -0.2188,  0.0077]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2061, -0.1641, -0.0640]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3008, -0.0859, -0.2559]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0049, -0.0869,  0.1680]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2695, -0.1348, -0.0762]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0347, -0.1387,  0.2383]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0136, -0.1641,  0.1641]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2871, -0.1221, -0.2393]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1226, -0.1904,  0.0503]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2891, -0.2051, -0.1177]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0986, -0.1885,  0.0352]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1777, -0.0645, -0.1689]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0108, -0.1992,  0.2100]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2412, -0.0938, -0.1494]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3379, -0.1104, -0.3320]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1758, -0.2002,  0.0474]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2129, -0.1021, -0.1416]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1079, -0.1650,  0.0255]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1001, -0.1074, -0.0325]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2080, -0.2344,  0.0157]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0869, -0.1865,  0.0693]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2227, -0.1040, -0.1582]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3086, -0.1377, -0.1768]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0610, -0.1562,  0.0645]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3242, -0.1426, -0.2256]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2373, -0.1670, -0.1035]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3242, -0.1777, -0.2227]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2178, -0.0962, -0.1338]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1572, -0.0713, -0.1270]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0547, -0.0854,  0.0106]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1904, -0.0845, -0.1162]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2734, -0.0123, -0.2852]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0640, -0.1367,  0.1147]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.1533,  0.0364]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0830, -0.0747, -0.0211]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2832, -0.0481, -0.2773]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2109, -0.1396, -0.1230]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0625, -0.1611,  0.2461]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0157, -0.1357,  0.1475]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1523, -0.1318, -0.0579]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1943, -0.2080, -0.0361]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0190, -0.1367,  0.1089]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0654, -0.1113,  0.0137]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1885, -0.1904, -0.0037]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1738, -0.1357, -0.0544]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1855, -0.1357, -0.0525]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2217, -0.1973, -0.1240]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2451, -0.0806, -0.1836]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2236, -0.1348, -0.1060]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1709, -0.1094, -0.1074]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0337, -0.1650,  0.2061]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0474, -0.1250,  0.1011]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0586, -0.0962,  0.1816]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2988, -0.1387, -0.2021]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0801, -0.1914,  0.2461]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2334, -0.1611, -0.1016]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2812, -0.1191, -0.2217]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2617, -0.1562, -0.0806]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1309, -0.1865,  0.0002]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0029, -0.1357,  0.1260]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2236, -0.0981, -0.1562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1367, -0.1396, -0.0259]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0898, -0.1328,  0.0645]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2246, -0.1221, -0.1523]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1797, -0.1006, -0.0747]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:20<00:05,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss: 1.073029891304348, val loss: 1.2220888137817383, val accuracy: 0.0\n",
      "model: output.logits=tensor([[ 0.4082, -0.0649, -0.4219]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2314, -0.1943, -0.0732]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3242, -0.0923, -0.3086]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2178, -0.2119, -0.0562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2393, -0.1914, -0.0674]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1729, -0.1641, -0.0283]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0178, -0.2012,  0.2236]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2754, -0.2002, -0.1406]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2139, -0.1475, -0.1670]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3320, -0.0317, -0.3496]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0125, -0.1211,  0.1689]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2090, -0.2188, -0.0422]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0527, -0.1699,  0.2441]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1787, -0.1631, -0.0479]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0576, -0.1885,  0.0732]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0309, -0.1670,  0.1338]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2871, -0.0569, -0.2949]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1226, -0.1196, -0.0176]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0481, -0.1709,  0.0894]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2812, -0.0549, -0.2988]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0293, -0.1592,  0.1152]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1045, -0.1387, -0.0388]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0206, -0.1572,  0.1592]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2100, -0.0776, -0.1680]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1475, -0.1709, -0.0366]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1260, -0.1143,  0.0060]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1250, -0.0679, -0.0713]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0503, -0.1157,  0.0728]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0522, -0.0923,  0.0549]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1611, -0.2285, -0.0045]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0732, -0.1807,  0.0996]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2021, -0.1406, -0.0527]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2266, -0.0947, -0.1206]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2441, -0.1318, -0.1641]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0923, -0.2715,  0.1602]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1904, -0.2227,  0.0165]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1816, -0.1504, -0.0737]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1826, -0.0913, -0.1318]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0200, -0.1963,  0.2227]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1631, -0.1162, -0.1133]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1113, -0.1260,  0.0125]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1270, -0.1250, -0.0359]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2363, -0.2061, -0.1191]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0674, -0.2695,  0.1865]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1230, -0.2217,  0.0972]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1865, -0.0579, -0.1729]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0016, -0.1660,  0.1699]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2305, -0.2246, -0.0041]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0569, -0.0908,  0.0304]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1807, -0.1060, -0.1147]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1484, -0.1348, -0.0364]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1514, -0.2754,  0.0815]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2354, -0.1689, -0.1279]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0077, -0.1680,  0.1973]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2100, -0.1670, -0.0820]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1650, -0.2734,  0.0598]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1943, -0.1982, -0.0635]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0222, -0.1611,  0.1514]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1670, -0.0864, -0.1475]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0393, -0.1338,  0.0811]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1143, -0.1465, -0.0188]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1289, -0.1729, -0.0625]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1621, -0.2412,  0.0439]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1875, -0.0752, -0.1582]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2256, -0.0986, -0.2178]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0938, -0.0292, -0.1240]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2158, -0.2334, -0.0096]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1777, -0.0038, -0.1514]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0308, -0.1147,  0.0859]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0898, -0.1777,  0.0684]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2500, -0.1260, -0.1924]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0087, -0.1934,  0.2158]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0264, -0.1758,  0.1270]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0500, -0.0698,  0.0493]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0391, -0.1758,  0.0938]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0405, -0.1689,  0.1079]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1631, -0.1084, -0.0933]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2012, -0.0791, -0.1709]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1914, -0.2656,  0.0181]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0287, -0.1719,  0.1846]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2461, -0.1318, -0.1328]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0952, -0.1143, -0.0272]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2617, -0.2227, -0.0991]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0270, -0.1436,  0.1191]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0126, -0.1270,  0.0820]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0742, -0.1611,  0.0786]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1924, -0.1167, -0.1523]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1719, -0.1621, -0.0413]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1021, -0.1060, -0.0177]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0223, -0.1602,  0.1738]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2500, -0.1309, -0.1299]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2188, -0.1904, -0.0588]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1475, -0.1138, -0.0898]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2988, -0.0791, -0.2715]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1650, -0.0791, -0.1670]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0977, -0.0815, -0.0449]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2324, -0.1709, -0.1211]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1484, -0.1147, -0.0674]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1816, -0.1641, -0.0175]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1001, -0.1504,  0.0332]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0732, -0.1621,  0.2168]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1084, -0.2100,  0.0527]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1040, -0.1729,  0.0654]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2695, -0.0664, -0.2520]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0129, -0.1777,  0.2227]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1162, -0.1689, -0.0019]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1260, -0.1128, -0.0981]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.0417, -0.1924]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2500, -0.1719, -0.1943]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3203, -0.0757, -0.3457]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0422, -0.1406,  0.0820]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2178, -0.1533, -0.0620]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1484, -0.1260, -0.0562]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0693, -0.1436,  0.0664]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1787, -0.1396, -0.0310]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1787, -0.1260, -0.0967]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1348, -0.1426, -0.0036]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3066, -0.1006, -0.2158]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1680, -0.2031, -0.0342]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1602, -0.0811, -0.1387]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0752, -0.1079,  0.0117]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0610, -0.1875,  0.2559]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2520, -0.2021, -0.1025]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1357, -0.1099, -0.0757]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2207, -0.1533, -0.0649]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0967, -0.1709,  0.0310]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3242, -0.1377, -0.2383]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2207, -0.0991, -0.1973]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2852, -0.1787, -0.1611]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1709, -0.0952, -0.0791]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2402, -0.1631, -0.1216]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1436, -0.2051, -0.0298]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1582, -0.1318, -0.0330]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0527, -0.1196,  0.0762]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0014, -0.1738,  0.1582]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0752, -0.1167, -0.0552]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0483, -0.1523,  0.1270]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2656, -0.0786, -0.2344]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0771, -0.1396,  0.2021]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0164, -0.1221,  0.1494]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2969, -0.0354, -0.3379]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2930, -0.0471, -0.3047]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0850, -0.1235,  0.0640]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1523, -0.1758, -0.1060]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3457, -0.0850, -0.3105]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3223, -0.1260, -0.2754]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1934, -0.2100,  0.0371]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1250, -0.0991, -0.0491]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1973, -0.1299, -0.0869]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2197, -0.0569, -0.2051]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2520, -0.1367, -0.1689]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0277, -0.1152,  0.1089]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2031, -0.1318, -0.0723]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0894, -0.1226, -0.0168]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1904, -0.1270, -0.1187]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0654, -0.1387,  0.0554]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0361, -0.1074,  0.1118]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1572, -0.1514, -0.0299]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0159, -0.1709,  0.1396]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0065, -0.1235,  0.1455]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1138, -0.2188,  0.1147]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1533, -0.2109,  0.0229]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2246, -0.1484, -0.1016]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0325, -0.1562,  0.2275]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2021, -0.1768, -0.0791]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1592, -0.1484, -0.0515]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0718, -0.0776,  0.2070]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2969, -0.0859, -0.2520]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1523, -0.1582, -0.0075]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1914, -0.1445, -0.0947]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2598, -0.1543, -0.1807]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2598, -0.2090, -0.1016]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2695, -0.0859, -0.2178]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2715, -0.0186, -0.2373]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0493, -0.0815,  0.0703]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2598, -0.0229, -0.3223]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2285, -0.1797, -0.1289]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2617, -0.1406, -0.1865]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0610, -0.1777,  0.1177]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1001, -0.1416,  0.0151]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1631, -0.1855, -0.0167]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0889, -0.1025,  0.0037]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1963, -0.0728, -0.1475]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2383, -0.1826, -0.1011]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0942, -0.0542, -0.0549]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1846, -0.1924, -0.0276]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1050, -0.1680,  0.0046]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0125, -0.0884,  0.1108]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1543, -0.2090,  0.0630]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1611, -0.1406, -0.0381]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2246, -0.1245, -0.1797]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0217, -0.1245,  0.1855]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.1865, -0.0167]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.1670, -0.1738,  0.3398]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0009, -0.1826,  0.2344]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2988, -0.1445, -0.2256]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0640, -0.2295,  0.1514]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2363, -0.1748, -0.0510]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0615, -0.2207,  0.1230]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1934, -0.0898, -0.1328]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0542, -0.2070,  0.2695]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2178, -0.1426, -0.1279]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2715, -0.1279, -0.2266]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0649, -0.2275,  0.1147]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1699, -0.0791, -0.1147]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0737, -0.1387,  0.0835]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0481, -0.0869,  0.0488]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1924, -0.2285,  0.0403]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0442, -0.1387,  0.0732]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1484, -0.1055, -0.0952]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2539, -0.1572, -0.1367]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0142, -0.1562,  0.0967]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3281, -0.1055, -0.2354]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1826, -0.1973, -0.0193]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2773, -0.1455, -0.2041]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1924, -0.1035, -0.1133]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1260, -0.0972, -0.0518]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0649, -0.1167,  0.0386]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1289, -0.1338, -0.0295]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2461, -0.0645, -0.2930]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0339, -0.1484,  0.1206]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1270, -0.2002,  0.0664]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1196, -0.0708, -0.0713]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2520, -0.0825, -0.2578]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2383, -0.1514, -0.0786]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0320, -0.2100,  0.2832]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0479, -0.1494,  0.2090]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1426, -0.1221, -0.0630]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1865, -0.2275, -0.0344]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0161, -0.1475,  0.1621]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0396, -0.1348,  0.0172]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 1.8066e-01, -2.0410e-01,  1.1444e-05]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0928, -0.1338,  0.0063]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2275, -0.2158, -0.0403]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2461, -0.1631, -0.0820]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2676, -0.1279, -0.1924]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2090, -0.1235, -0.1104]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1748, -0.1040, -0.1030]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0476, -0.1689,  0.2100]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0508, -0.1553,  0.0952]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0535, -0.1250,  0.2207]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.3086, -0.1318, -0.2041]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.1074, -0.1709,  0.2969]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1934, -0.1299, -0.0505]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2559, -0.1230, -0.2256]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([1], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.2461, -0.2070, -0.0557]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1670, -0.1748,  0.0444]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[-0.0388, -0.1235,  0.1514]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1904, -0.1318, -0.1318]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1021, -0.1475,  0.0063]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.0444, -0.1436,  0.0747]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:25<00:00,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: output.logits=tensor([[ 0.2031, -0.1279, -0.1089]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "model: output.logits=tensor([[ 0.1738, -0.0806, -0.1152]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<AddmmBackward0>) batch_labels=tensor([2], device='cuda:0')\n",
      "Epoch 4, train loss: 1.0623456027667983, val loss: 1.2264130115509033, val accuracy: 0.0\n",
      "Test loss: 1.2264130115509033, test accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epoch = 5\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.head.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=epoch * len(train_loader))\n",
    "#device = 'cuda:3'\n",
    "\n",
    "for i in tqdm(range(epoch)):\n",
    "    train_loss = train_epoch(model, device, train_loader, criterion, optimizer, scheduler)\n",
    "    val_loss, val_accuracy = evaluate_epoch(val_loader, model, criterion, device, phase='test')\n",
    "    print(f'Epoch {i}, train loss: {train_loss}, val loss: {val_loss}, val accuracy: {val_accuracy}')\n",
    "\n",
    "test_loss, test_accuracy = evaluate_epoch(test_loader, model, criterion, device, phase='test')\n",
    "print(f'Test loss: {test_loss}, test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StockDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the test dataset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mStockDataset\u001b[49m(data_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test dataset\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StockDataset' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "# Load the test dataset\n",
    "test_dataset = StockDataset(data_split=\"test\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "t1 = time.time()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    #for data, input_mask, labels in test_dataloader:\n",
    "    for data, labels in test_dataloader:\n",
    "        # Move data to the appropriate device\n",
    "        data = data.to(device, dtype=torch.float32)\n",
    "        labels = labels.to(device)\n",
    "        #input_mask = input_mask.to(device) if input_mask is not None else None\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(x_enc=data)\n",
    "\n",
    "        if output is None or output.logits is None:\n",
    "            raise ValueError(\"The model's output is None. Check the model's forward implementation.\")\n",
    "\n",
    "        logits: TimeseriesOutputs = output.logits\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(logits, dim=1)  # Get the predicted class indices\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Save all labels and predictions for metric computation\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "test_loss /= len(test_dataloader)\n",
    "accuracy = 100 * correct / total\n",
    "precision = precision_score(all_labels, all_predictions, average=\"weighted\")\n",
    "recall = recall_score(all_labels, all_predictions, average=\"weighted\")\n",
    "f1 = f1_score(all_labels, all_predictions, average=\"weighted\")\n",
    "\n",
    "# Print metrics\n",
    "\n",
    "print(f\"Num Test Set: {len(test_dataloader)}\")\n",
    "print(f\"Test Loss: {test_loss:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Time taken: {time.time() - t1:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
